{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "import time\n",
    "_wandb = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделать ваасермановский лосс\n",
    "Разобраться с dimm - что ето?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\work\\GAN_Z\\wandb\\run-20230902_164802-tlqkgdh7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xbostick/GAN-Z/runs/tlqkgdh7' target=\"_blank\">happy-terrain-32</a></strong> to <a href='https://wandb.ai/xbostick/GAN-Z' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xbostick/GAN-Z' target=\"_blank\">https://wandb.ai/xbostick/GAN-Z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xbostick/GAN-Z/runs/tlqkgdh7' target=\"_blank\">https://wandb.ai/xbostick/GAN-Z/runs/tlqkgdh7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if _wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"GAN-Z\",\n",
    "        \n",
    "        # track hyperparameters and run metadata\n",
    "        config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"GAN\",\n",
    "        \"dataset\": \"chr1\",\n",
    "        \"epochs\": 300,\n",
    "        }\n",
    "\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False # GPU Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = False # Generate generic data on the fly (ignores data_loc and data_start args)\n",
    "data_loc = Path(\"./data/\") # Data location\n",
    "epoch = 300\n",
    "disc_iters = 5 # Number of iterations to train discriminator for at each epoch\n",
    "latent_dim = 5 # Size of latent space\n",
    "gen_dim = 100 # Generator dimension parameter\n",
    "disc_dim = 100 # Discriminator dimension parameter\n",
    "gen_layers = 5\n",
    "disc_layer = 5\n",
    "batch_size = 100\n",
    "max_seq_len = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " gen_data = lib.models.resnet_generator(latent_vars, args.gen_dim, args.max_seq_len, data_enc_dim, args.annotate)\n",
    "  data_enc_dim = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_DNA(part):\n",
    "    seq = []\n",
    "    for i in part:\n",
    "        match i:\n",
    "                case 0:\n",
    "                    seq.append([1,0,0,0,0])\n",
    "                case 1:\n",
    "                    seq.append([0,1,0,0,0])\n",
    "                case 2:\n",
    "                    seq.append([0,0,1,0,0])\n",
    "                case 3:\n",
    "                    seq.append([0,0,0,1,0])\n",
    "                case 4:\n",
    "                    seq.append([0,0,0,0,1])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_ohe_DNA(part):\n",
    "    seq = []\n",
    "    for i in part:\n",
    "        match i:\n",
    "                case [1,0,0,0,0]:\n",
    "                    seq.append(0)\n",
    "                case [0,1,0,0,0]:\n",
    "                    seq.append(1)\n",
    "                case [0,0,1,0,0]:\n",
    "                    seq.append(2)\n",
    "                case [0,0,0,1,0]:\n",
    "                    seq.append(3)\n",
    "                case [0,0,0,0,1]:\n",
    "                    seq.append(4)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_ohe_DNA(GenData[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "o = reverse_ohe_DNA(GenData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.numpy() == [1,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_13088\\752960707.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    }
   ],
   "source": [
    "noise = Variable(torch.randn((1,1000))).cuda()\n",
    "out = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_13088\\752960707.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 2, 0, 3, 2, 0, 0, 3, 2, 1, 0, 3, 3, 1, 0, 2, 3, 3, 1, 0, 0, 3,\n",
       "       3, 0, 0, 3, 2, 0, 3, 2, 1, 3, 2, 1, 3, 2, 0, 3, 2, 1, 0, 0, 3, 2,\n",
       "       1, 0, 2, 0, 1, 0, 1, 3, 2, 0, 3, 3, 0, 0, 3, 1, 1, 0, 3, 2, 1, 3,\n",
       "       2, 0, 3, 2, 1, 0, 2, 3, 3, 1, 0, 0, 3, 2, 1, 0, 2, 3, 3, 2, 0, 3,\n",
       "       2, 1, 0, 3, 1, 1, 0, 2, 1, 3, 1, 0, 0, 2, 3, 3, 1, 0, 0, 3, 1, 1,\n",
       "       0, 0, 3, 2, 0, 0, 3, 1, 1, 0, 2, 0, 1, 0, 0, 3, 2, 1, 0, 0, 3, 2,\n",
       "       1, 3, 2, 1, 3, 1, 3, 1, 0, 3, 3, 1, 0, 3, 2, 1, 3, 1, 0, 2, 1, 3,\n",
       "       2, 0, 3, 2, 1, 0, 2, 3, 1, 1, 0, 0, 3, 1, 0, 0, 3, 2, 0, 3, 2, 1,\n",
       "       3, 2, 1, 0, 0, 3, 2, 1, 0, 3, 3, 2, 0, 3, 2, 0, 0, 3, 2, 1, 3, 2,\n",
       "       1, 0, 3, 3, 2, 0, 3, 3, 1, 0, 0, 3, 3, 1, 0, 3, 2, 1, 0, 2, 3, 3,\n",
       "       1, 1, 0, 2, 3, 2, 0, 3, 2, 1, 3, 2, 0, 3, 2, 1, 3, 2, 0, 3, 2, 0,\n",
       "       3, 2, 1, 0, 2, 3, 2, 0, 3, 3, 1, 0, 0, 3, 2, 0, 3, 2, 1, 0, 0, 3,\n",
       "       2, 0, 3, 2, 1, 3, 2, 0, 3, 2, 1, 3, 1, 0, 0, 3, 2, 0, 0, 3, 2, 1,\n",
       "       0, 3, 3, 1, 0, 3, 2, 1, 3, 2, 0, 3, 3, 1, 1, 0, 3, 3, 2, 0, 3, 2,\n",
       "       1, 0, 2, 3, 2, 0, 3, 2, 0, 3, 2, 1, 0, 0, 3, 2, 0, 0, 2, 1, 1, 0,\n",
       "       0, 3, 2, 1, 0, 2, 3, 2, 0, 3, 2, 1, 3, 2, 0, 3, 2, 1, 3, 3, 2, 0,\n",
       "       3, 2, 1, 3, 2, 0, 3, 2, 1, 3, 2, 3, 3, 1, 0, 0, 3, 2, 0, 3, 2, 1,\n",
       "       3, 2, 1, 0, 3, 2, 1, 0, 2, 3, 2, 0, 3, 2, 1, 0, 0, 3, 3, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 3, 3, 1, 0,\n",
       "       3, 3, 1, 0, 0, 3, 2, 1, 0, 2, 3, 2, 0, 3, 2, 1, 0, 2, 3, 3, 1, 1,\n",
       "       0, 0, 3, 2, 1, 3, 2, 1, 3, 0, 0, 3, 1, 0, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 0, 3, 3, 1, 0, 3, 3, 2, 0, 3,\n",
       "       2, 1, 3, 2, 0, 3, 3, 2, 1, 3, 2, 0, 3, 3, 1, 0, 3, 2, 1, 3, 2, 1,\n",
       "       3, 2, 0, 3, 2, 1, 0, 3, 2, 0, 3, 2, 1, 3, 2, 1, 0, 2, 0, 2, 1, 3,\n",
       "       2, 0, 3, 2, 1, 0, 0, 3, 3, 1, 0, 0, 3, 2, 1, 3, 2, 1, 0, 2, 1, 0,\n",
       "       0, 3, 2, 1, 0, 0, 3, 2, 1, 0, 2, 0, 1, 3, 1, 0, 2, 3, 2, 1, 0, 3,\n",
       "       2, 0, 3, 2, 1, 3, 2, 1, 0, 3, 3, 1, 0, 3, 2, 1, 1, 0, 0, 3, 1, 0,\n",
       "       0, 3, 2, 1, 3, 2, 1, 0, 0, 3, 3, 1, 0, 3, 3, 1, 0, 0, 2, 3, 2, 1,\n",
       "       0, 2, 3, 3, 1, 3, 2, 0, 1, 3, 1, 0, 1, 3, 0, 3, 2, 1, 1, 3, 1, 0,\n",
       "       3, 2, 0, 3, 2, 1, 0, 0, 3, 3, 1, 0, 3, 2, 1, 3, 2, 1, 3, 2, 0, 3,\n",
       "       2, 1, 0, 3, 3, 1, 1, 0, 0, 3, 3, 1, 0, 3, 3, 1, 0, 0, 3, 2, 1, 3,\n",
       "       2, 0, 3, 3, 1, 0, 3, 3, 1, 0, 0, 3, 2, 1, 3, 2, 0, 0, 3, 2, 1, 3,\n",
       "       3, 1, 0, 3, 3, 0, 0, 3, 1, 0, 0, 3, 2, 1, 1, 0, 0, 3, 2, 1, 3, 2,\n",
       "       0, 3, 0, 1, 0, 1, 0, 2, 3, 3, 1, 0, 3, 2, 0, 3, 2, 1, 3, 2, 0, 3,\n",
       "       2, 1, 0, 2, 3, 1, 1, 0, 0, 3, 2, 0, 3, 2, 0, 0, 3, 2, 0, 3, 2, 1,\n",
       "       0, 0, 0, 3, 3, 1, 0, 3, 2, 1, 0, 0, 3, 2, 1, 3, 2, 0, 3, 2, 0, 3,\n",
       "       2, 1, 0, 2, 1, 0, 0, 3, 2, 1, 0, 2, 3, 1, 0, 1, 0, 2, 3, 2, 0, 3,\n",
       "       3, 1, 0, 3, 3, 1, 0, 3, 2, 1, 0, 1, 0, 0, 3, 2, 1, 3, 0, 0, 3, 3,\n",
       "       1, 0, 3, 3, 1, 0, 3, 2, 1, 3, 0, 0, 3, 2, 1, 0, 2, 1, 3, 2, 0, 3,\n",
       "       2, 1, 0, 2, 3, 2, 1, 3, 2, 1, 0, 0, 3, 2, 1, 0, 3, 1, 1, 0, 0, 3,\n",
       "       3, 1, 0, 0, 2, 3, 1, 1, 0, 0, 3, 2, 1, 0, 2, 0, 3, 2, 1, 3, 1, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 2, 0,\n",
       "       3, 3, 1, 0, 0, 3, 3, 0, 0, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 2, 1, 3, 1, 0, 0, 3, 2, 1,\n",
       "       0, 0, 3, 1, 1, 0, 3, 2, 1, 3, 2, 0, 3, 2, 1, 0, 2, 1, 3, 2, 0, 3,\n",
       "       2, 0, 3, 2, 0, 3, 2, 1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(generator(noise).detach().cpu().numpy(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_vocab = {\"A\":0,\n",
    "             \"C\":1,\n",
    "             \"G\":2,\n",
    "             \"T\":3,\n",
    "             \"N\":4} # catch-all auxiliary token\n",
    "\n",
    "class GenomicData(Dataset):\n",
    "    def __init__(self, path, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        with open(path) as fasta_file:  # Will close handle cleanly\n",
    "            seq_record = {}\n",
    "            seq_record[\"lengths\"] = []\n",
    "            seq_record[\"seq\"] = []\n",
    "\n",
    "            for seq_rec in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
    "                seq_record[\"lengths\"].append(len(seq_rec.seq))\n",
    "                seq_record[\"seq\"].append(seq_rec.seq)\n",
    "        self.len = int(seq_record[\"lengths\"][0])\n",
    "        self.coded_seq = []\n",
    "        for one in list(seq_record[\"seq\"][0]):\n",
    "            try:\n",
    "                self.coded_seq.append(dna_vocab[one.upper()])\n",
    "            except:\n",
    "                print(one)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.len/self.seq_len)#int(np.round((self.len - self.seq_len)/100))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(ohe_DNA(self.coded_seq[idx* self.seq_len:(idx+1)*self.seq_len]))\n",
    "\n",
    "\n",
    "GenData = GenomicData(\"./data/chr1.fa\", max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenData[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 сверточных слоев с skip connection residual factor 0.3.\n",
    "В сверточном слое 100 фильтров ядро 5 stribe 1\n",
    "adam optimazer и wasserstein loss(WGAN) and lr 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_new(nn.Module):\n",
    "    def __init__(self,  latent_vars, gen_dim, max_seq_len, annotated=False, res_layers=5):\n",
    "        super(Generator_new, self).__init__()\n",
    "        self.input_size = latent_vars.shape\n",
    "        self.output_size = gen_dim * max_seq_len\n",
    "        self.seq_len = max_seq_len\n",
    "        self.gen_dim = gen_dim\n",
    "        self.res_layer = res_layers\n",
    "        #self.conv1 = nn.Conv1d(3,6,5,1)\n",
    "        self.con1 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con2 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con3 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con4 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con5 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv1d(gen_dim,5,5,1, padding = 'same'),\n",
    "                        nn.ReLU())\n",
    "        # self.con_array = [\n",
    "        #     self.con1,\n",
    "        #     self.con2,\n",
    "        #     self.con3,\n",
    "        #     self.con4,\n",
    "        #     self.con5,\n",
    "        # ]\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()#nn.Sigmoid()\n",
    "        self.linear = nn.Linear(1,100)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        x = self.linear(x) \n",
    "        x = torch.transpose(x , 0, 1)\n",
    "        _input = x\n",
    "        \n",
    "        out = self.con1(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "        \n",
    "        out = self.con2(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con3(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con4(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con5(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        output = self.conv1(_input)\n",
    "        output = torch.transpose(output, 0, 1)\n",
    "        output = self.softmax(output)\n",
    "        output = torch.transpose(output, 0, 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critical_new(nn.Module):\n",
    "    def __init__(self,  latent_vars, gen_dim, max_seq_len, annotated=False, res_layers=5):\n",
    "        super(Critical_new, self).__init__()\n",
    "        self.input_size = latent_vars.shape\n",
    "        self.output_size = gen_dim * max_seq_len\n",
    "        self.seq_len = max_seq_len\n",
    "        self.gen_dim = gen_dim\n",
    "        self.res_layer = res_layers\n",
    "        #self.conv1 = nn.Conv1d(3,6,5,1)\n",
    "        self.con1 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con2 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con3 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con4 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con5 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv1d(5, gen_dim,5,1, padding = 'same'),\n",
    "                        nn.ReLU())\n",
    "        # self.con_array = [\n",
    "        #     self.con1,\n",
    "        #     self.con2,\n",
    "        #     self.con3,\n",
    "        #     self.con4,\n",
    "        #     self.con5,\n",
    "        # ]\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(100,1)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        _input = self.conv1(x)\n",
    "        \n",
    "        out = self.con1(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con2(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con3(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con4(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con5(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        output = torch.transpose(_input, 0, 1)\n",
    "        output = self.linear(output)\n",
    "        output = torch.transpose(output, 0, 1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vars = torch.randn([10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator= Generator_new(latent_vars,gen_dim,max_seq_len)\n",
    "discriminator = Critical_new(latent_vars,gen_dim,max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load = True\n",
    "if Load:\n",
    "    generator.load_state_dict(torch.load(\"./models/generator.mod\"))\n",
    "    generator.eval()\n",
    "\n",
    "    discriminator.load_state_dict(torch.load(\"./models/discriminator.mod\"))\n",
    "    discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.cuda()\n",
    "# out = generator(z)\n",
    "# discriminator.cuda()\n",
    "# discriminator(out).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    #adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggested default - beta parameters (decay of first order momentum of gradients)\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "# suggested default - learning rate\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas = (b1,b2) )\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _wandb:\n",
    "    wandb.watch(generator, log_freq=100)\n",
    "    wandb.watch(discriminator, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad(model):\n",
    "    for param in model.parameters():\n",
    "        param.grad = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1)))\n",
    "        # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_data))\n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    fake = Variable(Tensor(1,1000).fill_(1.0), requires_grad=False)\n",
    "        # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "            outputs=d_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=fake,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WandbLogging(LogData,StartTime, Delay):\n",
    "    NowTime = time.perf_counter()\n",
    "    if NowTime - StartTime > Delay:\n",
    "        wandb.log(LogData)\n",
    "        return NowTime\n",
    "    else:\n",
    "        return StartTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba1aec372f34501a77791bb9ce7b3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_2300\\752960707.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_loss: -0.002578720450401306; G_loss: -0.19506196677684784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62438f081e4b402c909300b2ae5d9c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_loss: 0.05816639959812164; G_loss: -0.19159919023513794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06ca473cda04c1b928ae96d0c514aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_loss: 0.0005264878273010254; G_loss: -0.1460689753293991\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa2a41a2d974cebb893781f84daa408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m#gradient_penalty = compute_gradient_penalty(discriminator, real_data, fake_data)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m critics_loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mmean(critics_real) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmean(critics_fake) \u001b[39m#+ 10 * gradient_penalty\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m critics_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     28\u001b[0m optimizer_D\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     30\u001b[0m \u001b[39m# Weight clipping\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\mambaforge\\envs\\GAN\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\mambaforge\\envs\\GAN\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clear_output()\n",
    "n_epochs = 10 # suggested default = 200\n",
    "for epoch in range(n_epochs):\n",
    "    dataloader = None\n",
    "    dataloader = DataLoader(GenData,6,drop_last=True, shuffle = True)\n",
    "    StartTime = time.perf_counter()\n",
    "    for i in tqdm(dataloader):\n",
    "        train_data = i.cuda()\n",
    "        #   Critical forward-loss-backward-update\n",
    "        for j in range(5):\n",
    "\n",
    "            # Sample data\n",
    "            noise = Variable(torch.randn((1,1000))).cuda()# Random sampling Tensor(batch_size, latent_dim) of Gaussian distribution\n",
    "        \n",
    "            # real_data = torch.reshape(train_data[j],(1,1000))\n",
    "            real_data = torch.transpose(train_data[j],0,1)\n",
    "            real_data = Variable(real_data)\n",
    "\n",
    "            #generic\n",
    "            fake_data = generator(noise)\n",
    "            critics_real = discriminator(real_data)\n",
    "            critics_fake = discriminator(fake_data)\n",
    "\n",
    "            #gradient_penalty = compute_gradient_penalty(discriminator, real_data, fake_data)\n",
    "            critics_loss = -torch.mean(critics_real) + torch.mean(critics_fake) #+ 10 * gradient_penalty\n",
    "            \n",
    "            critics_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Weight clipping\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            # Housekeeping - reset gradient\n",
    "            reset_grad(generator)\n",
    "            reset_grad(discriminator)\n",
    "\n",
    "        #   Generator forward-loss-backward-update\n",
    "        \n",
    "        noise = Variable(torch.randn((1,1000))).cuda()# Random sampling Tensor(batch_size, latent_dim) of Gaussian distribution\n",
    "        #real_data = torch.reshape(train_data[j+1],(1,1000))\n",
    "        real_data = Variable(real_data)\n",
    "        #real_data = imgs[\"generator\"].type(Tensor)\n",
    "\n",
    "        fake_data = generator(noise)\n",
    "        critics_fake = discriminator(fake_data)\n",
    "\n",
    "        generator_loss = -torch.mean(critics_fake)\n",
    "        \n",
    "        generator_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        reset_grad(generator)\n",
    "        reset_grad(discriminator)\n",
    "\n",
    "        if _wandb:\n",
    "            table = wandb.Histogram(np_histogram = np.histogram(np.argmax(generator(noise).detach().cpu().numpy(),0)))\n",
    "            WandbLogDict = {\"Epoch\": epoch+1, \"Critics_loss\": critics_loss.item(), \"Generator_loss\": generator_loss.item(),\"Results\": table}\n",
    "            StartTime = WandbLogging(WandbLogDict, StartTime, 120)\n",
    "            \n",
    "\n",
    "    print('D_loss: {}; G_loss: {}'\n",
    "              .format(critics_loss.item(),  generator_loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c19ead3f224bd4bdcb5eb9180fca8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Critics_loss</td><td>▆▃▅▇▅▆▆▆▅▆▅▆▆▅▆▆▅▅█▆▆▁▆▁▆█▆▅▆▆▅▇▆▅▆▆▆▅▅▆</td></tr><tr><td>Epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆██</td></tr><tr><td>Generator_loss</td><td>▅▂▆▃▇█▇▆▆▂▂▂▁▁▃▁▁▂▂▄▃▂▃▂▅▄▂▂▂▃▃▃▂▃▃▃▃▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Critics_loss</td><td>-0.01131</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>Generator_loss</td><td>-0.15468</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-terrain-32</strong> at: <a href='https://wandb.ai/xbostick/GAN-Z/runs/tlqkgdh7' target=\"_blank\">https://wandb.ai/xbostick/GAN-Z/runs/tlqkgdh7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230902_164802-tlqkgdh7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), \"./models/generator.mod\")\n",
    "torch.save(discriminator.state_dict(), \"./models/discriminator.mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(generator):\n",
    "    noise = Variable(torch.randn((1,1000))).cuda()\n",
    "    OheSeq = generator(noise).detach().cpu().numpy()\n",
    "    return np.argmax(OheSeq,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GC content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GC_Content(ohe_seq):\n",
    "    return (sum(ohe_seq == dna_vocab[\"G\"]) + sum(ohe_seq == dna_vocab[\"C\"]))/len(ohe_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_13088\\752960707.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    }
   ],
   "source": [
    "o = generate_seq(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 3, 2, 0, 0, 3, 2, 0, 3, 2, 0, 3, 2, 1, 3, 2, 1, 3, 2, 0,\n",
       "       3, 2, 1, 3, 2, 1, 0, 0, 3, 3, 1, 0, 3, 3, 1, 0, 3, 2, 1, 3, 2, 0,\n",
       "       3, 2, 0, 3, 3, 1, 0, 0, 3, 2, 0, 3, 3, 1, 0, 3, 2, 0, 3, 2, 1, 3,\n",
       "       2, 1, 3, 2, 1, 3, 2, 0, 0, 3, 2, 0, 3, 2, 1, 0, 2, 1, 0, 0, 3, 2,\n",
       "       0, 3, 2, 1, 3, 2, 0, 0, 3, 2, 1, 3, 2, 0, 3, 2, 1, 0, 3, 2, 1, 0,\n",
       "       1, 3, 2, 1, 3, 2, 0, 3, 3, 1, 0, 0, 3, 2, 1, 3, 2, 0, 3, 2, 1, 3,\n",
       "       2, 0, 3, 2, 1, 0, 2, 2, 0, 3, 2, 1, 0, 0, 3, 2, 1, 3, 2, 0, 3, 3,\n",
       "       1, 0, 3, 3, 2, 0, 3, 2, 1, 3, 3, 2, 0, 3, 2, 1, 3, 2, 3, 3, 1, 0,\n",
       "       0, 3, 3, 1, 0, 0, 3, 1, 0, 0, 3, 3, 1, 0, 3, 3, 2, 0, 3, 2, 1, 0,\n",
       "       3, 2, 1, 3, 1, 0, 0, 3, 2, 1, 0, 3, 2, 1, 0, 2, 2, 3, 1, 0, 0, 3,\n",
       "       2, 0, 3, 2, 1, 3, 2, 1, 3, 1, 0, 2, 0, 3, 3, 1, 0, 3, 2, 1, 3, 2,\n",
       "       0, 3, 2, 1, 3, 2, 0, 3, 2, 0, 3, 2, 1, 0, 0, 3, 2, 1, 3, 2, 0, 3,\n",
       "       2, 1, 3, 1, 3, 1, 0, 0, 3, 1, 1, 0, 3, 2, 1, 0, 1, 3, 2, 0, 3, 2,\n",
       "       1, 3, 2, 0, 0, 3, 3, 1, 0, 3, 2, 1, 3, 3, 0, 0, 3, 2, 1, 0, 2, 3,\n",
       "       0, 3, 2, 0, 3, 2, 1, 0, 3, 1, 0, 3, 2, 1, 3, 3, 1, 0, 0, 3, 2, 0,\n",
       "       3, 2, 0, 3, 2, 1, 3, 2, 0, 3, 2, 1, 3, 1, 1, 0, 3, 3, 1, 3, 2, 0,\n",
       "       3, 3, 1, 0, 3, 2, 1, 0, 0, 3, 2, 1, 1, 0, 0, 3, 2, 1, 0, 3, 3, 1,\n",
       "       0, 0, 3, 1, 0, 1, 3, 2, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 1, 0, 0, 3, 3, 1, 0, 3, 3, 1, 0, 3,\n",
       "       1, 1, 0, 3, 3, 1, 0, 3, 2, 1, 1, 0, 0, 3, 1, 0, 0, 3, 2, 1, 0, 2,\n",
       "       0, 3, 1, 0, 3, 2, 1, 1, 0, 1, 3, 2, 0, 2, 2, 1, 3, 1, 3, 2, 0, 3,\n",
       "       3, 1, 0, 2, 3, 1, 1, 0, 0, 3, 3, 1, 1, 0, 0, 3, 2, 0, 3, 2, 1, 0,\n",
       "       2, 1, 3, 0, 0, 3, 3, 1, 0, 3, 2, 1, 0, 2, 3, 2, 0, 3, 3, 1, 0, 3,\n",
       "       3, 1, 0, 3, 2, 0, 0, 3, 2, 1, 0, 3, 0, 0, 3, 3, 1, 0, 3, 2, 1, 3,\n",
       "       2, 0, 3, 3, 1, 0, 2, 0, 3, 3, 1, 0, 3, 3, 3, 0, 0, 3, 3, 1, 0, 3,\n",
       "       3, 1, 0, 0, 2, 3, 3, 1, 0, 3, 2, 1, 0, 3, 0, 1, 3, 2, 3, 0, 0, 3,\n",
       "       2, 1, 3, 2, 0, 0, 3, 2, 0, 3, 3, 1, 0, 3, 2, 1, 0, 0, 3, 2, 1, 3,\n",
       "       2, 0, 0, 3, 1, 0, 1, 0, 0, 3, 3, 0, 0, 3, 2, 0, 3, 2, 0, 3, 2, 1,\n",
       "       3, 2, 0, 3, 2, 1, 0, 3, 2, 1, 0, 0, 3, 2, 1, 0, 2, 1, 1, 0, 0, 3,\n",
       "       3, 1, 0, 3, 2, 1, 0, 3, 2, 1, 0, 3, 0, 0, 0, 2, 3, 2, 0, 3, 2, 1,\n",
       "       0, 3, 2, 1, 3, 2, 0, 3, 3, 1, 0, 0, 3, 2, 1, 3, 2, 0, 1, 3, 2, 1,\n",
       "       0, 0, 3, 3, 1, 0, 3, 2, 0, 3, 3, 1, 0, 3, 3, 1, 0, 3, 2, 1, 0, 3,\n",
       "       2, 0, 3, 3, 2, 0, 3, 2, 1, 0, 0, 3, 3, 1, 0, 3, 3, 2, 0, 3, 2, 1,\n",
       "       0, 3, 1, 0, 0, 3, 2, 0, 3, 3, 1, 0, 3, 2, 1, 3, 1, 0, 0, 3, 2, 1,\n",
       "       0, 0, 3, 1, 0, 3, 3, 1, 0, 3, 1, 0, 3, 2, 0, 3, 3, 1, 0, 3, 2, 1,\n",
       "       0, 2, 0, 2, 3, 1, 3, 2, 0, 3, 2, 0, 3, 2, 1, 3, 2, 0, 0, 0, 2, 3,\n",
       "       1, 0, 0, 3, 3, 1, 0, 0, 3, 2, 1, 3, 2, 3, 3, 1, 0, 3, 3, 1, 0, 0,\n",
       "       2, 0, 1, 0, 0, 3, 2, 1, 0, 3, 2, 1, 0, 2, 3, 2, 1, 3, 2, 0, 3, 2,\n",
       "       1, 1, 0, 0, 3, 2, 1, 3, 2, 0, 3, 2, 1, 0, 0, 3, 3, 1, 0, 0, 2, 1,\n",
       "       1, 0, 3, 3, 1, 1, 0, 0, 3, 2, 0, 3, 2, 1, 0, 3, 2, 3, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 3, 3, 0, 0,\n",
       "       3, 2, 1, 0, 2, 3, 3, 2, 0, 3, 2, 0, 3, 3, 2, 0, 3, 2, 1, 0, 3, 2,\n",
       "       1, 0, 2, 0, 3, 0, 1, 3, 1, 0, 0, 1, 3, 1, 0, 3, 2, 1, 0, 2, 3, 1,\n",
       "       1, 0, 3, 2, 1, 0, 3, 3, 1, 0, 3, 3, 1, 0, 3, 3, 1, 0, 0, 3, 2, 1,\n",
       "       0, 0, 3, 2, 1, 3, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 1, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_Content(GenData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(GenData[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_ohe_DNA(GenData[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.397"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_Content(np.array(reverse_ohe_DNA(GenData[1100].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(o == 3) + sum(o == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1., 3., 2., 0., 1., 1., 1., 3., 1., 1., 0., 3., 3., 2., 0.,\n",
       "        2., 1., 3., 2., 0., 3., 3., 2., 2., 1., 0., 3., 3., 2., 2., 1., 1., 0.,\n",
       "        3., 1., 1., 1., 1., 0., 2., 0., 1., 0., 2., 1., 0., 2., 0., 2., 1., 3.,\n",
       "        2., 0., 0., 0., 0., 0., 2., 1., 0., 1., 3., 2., 2., 3., 3., 2., 3., 0.,\n",
       "        0., 1., 0., 3., 2., 1., 3., 3., 2., 2., 0., 1., 0., 1., 3., 2., 1., 3.,\n",
       "        2., 3., 2., 2., 2., 2., 1., 1., 1., 0., 1., 0., 1., 0., 2., 0., 2., 1.,\n",
       "        1., 3., 2., 1., 3., 1., 1., 0., 2., 1., 1., 0., 2., 0., 2., 0., 0., 2.,\n",
       "        0., 2., 3., 2., 0., 1., 3., 2., 2., 1., 1., 0., 2., 3., 3., 1., 1., 1.,\n",
       "        2., 1., 2., 3., 3., 1., 0., 3., 3., 3., 2., 1., 3., 1., 1., 0., 2., 3.,\n",
       "        3., 1., 1., 1., 0., 1., 0., 1., 3., 1., 0., 1., 3., 1., 2., 1., 3., 1.,\n",
       "        2., 1., 0., 3., 2., 1., 3., 1., 1., 1., 3., 0., 1., 3., 2., 3., 2., 0.,\n",
       "        2., 2., 0., 2., 0., 0., 2., 1., 1., 0., 2., 1., 2., 3., 1., 1., 2., 2.,\n",
       "        1., 3., 2., 0., 2., 3., 2., 0., 0., 0., 1., 0., 0., 2., 1., 1., 0., 1.,\n",
       "        3., 1., 1., 0., 3., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 2., 0.,\n",
       "        1., 0., 0., 0., 2., 2., 2., 2., 0., 3., 1., 0., 0., 2., 2., 2., 0., 0.,\n",
       "        1., 3., 0., 3., 1., 1., 1., 0., 3., 1., 3., 1., 0., 2., 2., 0., 3., 1.,\n",
       "        0., 3., 1., 0., 2., 0., 0., 1., 1., 0., 2., 3., 2., 1., 1., 1., 0., 1.,\n",
       "        3., 0., 3., 3., 2., 2., 2., 0., 3., 0., 1., 0., 1., 3., 2., 3., 2., 2.,\n",
       "        2., 3., 1., 1., 3., 3., 1., 2., 3., 2., 3., 2., 1., 1., 0., 3., 1., 0.,\n",
       "        2., 2., 2., 2., 0., 0., 1., 0., 2., 2., 3., 0., 1., 3., 0., 0., 3., 2.,\n",
       "        3., 2., 0., 3., 3., 1., 0., 3., 2., 2., 0., 0., 3., 3., 3., 0., 1., 0.,\n",
       "        3., 0., 2., 3., 3., 1., 0., 2., 0., 0., 0., 0., 3., 2., 3., 0., 3., 3.,\n",
       "        3., 3., 1., 1., 3., 1., 3., 1., 3., 1., 3., 2., 2., 1., 1., 0., 1., 3.,\n",
       "        3., 1., 0., 3., 3., 3., 3., 1., 3., 1., 1., 3., 1., 1., 0., 3., 1., 1.,\n",
       "        1., 3., 2., 0., 2., 0., 0., 3., 1., 3., 2., 0., 3., 3., 2., 3., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 0., 3., 1., 3., 3., 1., 0., 2., 1., 3., 3., 3., 1.,\n",
       "        1., 1., 3., 2., 1., 0., 3., 1., 3., 1., 1., 0., 2., 2., 0., 0., 2., 3.,\n",
       "        3., 2., 3., 1., 3., 3., 2., 2., 2., 1., 0., 2., 3., 2., 0., 3., 0., 3.,\n",
       "        2., 2., 3., 3., 3., 2., 0., 0., 3., 1., 3., 2., 3., 2., 3., 1., 1., 1.,\n",
       "        1., 0., 1., 3., 1., 0., 0., 0., 3., 1., 3., 1., 0., 3., 2., 3., 1., 0.,\n",
       "        0., 0., 3., 3., 2., 3., 0., 0., 1., 1., 3., 1., 1., 0., 0., 3., 2., 3.,\n",
       "        3., 2., 2., 2., 2., 2., 3., 2., 2., 2., 0., 1., 1., 3., 2., 2., 3., 2.,\n",
       "        2., 2., 0., 2., 2., 3., 2., 0., 0., 3., 2., 2., 0., 3., 1., 0., 3., 2.,\n",
       "        2., 2., 2., 2., 3., 2., 2., 0., 3., 3., 3., 1., 1., 1., 1., 1., 3., 3.,\n",
       "        3., 2., 1., 3., 2., 1., 3., 2., 3., 3., 1., 3., 1., 0., 3., 2., 0., 3.,\n",
       "        0., 2., 0., 2., 3., 3., 1., 3., 1., 0., 3., 2., 0., 2., 0., 3., 1., 3.,\n",
       "        2., 2., 3., 3., 2., 3., 3., 3., 0., 0., 0., 0., 2., 3., 2., 3., 2., 3.,\n",
       "        2., 0., 1., 0., 1., 1., 3., 1., 1., 1., 1., 1., 3., 2., 1., 1., 0., 3.,\n",
       "        3., 1., 1., 0., 2., 1., 1., 0., 3., 2., 3., 0., 0., 2., 0., 1., 0., 3.,\n",
       "        2., 1., 1., 3., 2., 1., 3., 3., 1., 1., 1., 1., 3., 3., 1., 1., 2., 1.,\n",
       "        3., 3., 1., 3., 2., 1., 1., 0., 3., 2., 0., 0., 3., 0., 3., 0., 0., 2.,\n",
       "        3., 3., 3., 1., 1., 3., 2., 0., 2., 2., 1., 3., 3., 1., 1., 1., 1., 0.,\n",
       "        2., 2., 0., 2., 1., 1., 2., 0., 2., 1., 0., 2., 0., 3., 3., 1., 1., 0.,\n",
       "        2., 1., 0., 3., 1., 0., 3., 2., 1., 3., 3., 3., 1., 1., 2., 3., 0., 1.,\n",
       "        0., 2., 1., 1., 3., 2., 1., 0., 2., 0., 0., 1., 3., 2., 3., 2., 0., 2.,\n",
       "        1., 1., 0., 0., 3., 3., 0., 2., 0., 1., 1., 3., 3., 3., 3., 3., 1., 3.,\n",
       "        3., 3., 0., 3., 0., 0., 0., 3., 3., 0., 1., 1., 1., 0., 2., 3., 2., 3.,\n",
       "        1., 3., 2., 2., 3., 0., 3., 3., 3., 3., 3., 3., 3., 0., 3., 0., 2., 1.,\n",
       "        0., 2., 3., 2., 2., 1., 0., 0., 0., 0., 1., 2., 2., 0., 1., 3., 0., 0.,\n",
       "        3., 0., 1., 0., 2., 2., 3., 2., 0., 1., 0., 3., 3., 3., 3., 1., 0., 2.,\n",
       "        1., 0., 3., 1., 3., 1., 1., 0., 2., 1., 1., 3., 2., 2., 1., 3., 1., 3.,\n",
       "        1., 3., 1., 3., 2., 1., 0., 2., 3., 2., 3., 1., 3., 2., 1., 0., 3., 2.,\n",
       "        2., 0., 2., 3., 1., 3., 3., 2., 2., 0., 2., 0., 0., 0., 1., 0., 1., 3.,\n",
       "        2., 0., 1., 0., 3., 2., 3., 1., 1., 0., 3., 3., 1., 1., 1., 0., 2., 2.,\n",
       "        3., 3., 2., 3., 2., 2., 3., 0., 2., 3., 3., 2., 2., 3., 2., 3., 3., 2.,\n",
       "        3., 2., 2., 3., 2., 2., 1., 1., 1., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.Linear(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Variable(torch.randn((1000,1)))\n",
    "o = l(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_2300\\752960707.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    }
   ],
   "source": [
    "noise = Variable(torch.randn((1,1000))).cuda()\n",
    "o = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_ohe_DNA(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = generator(noise)\n",
    "out.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.0168753"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 1., 0., 0., 3., 3., 0., 3., 0., 0., 3., 3., 3., 1., 0., 3., 0.,\n",
       "        2., 0., 3., 2., 2., 0., 0., 0., 2., 3., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 0., 0., 0., 0., 0., 2., 0., 0., 2., 0., 0.,\n",
       "        2., 2., 0., 0., 0., 3., 0., 0., 0., 0., 3., 0., 0., 3., 0., 1., 0., 3.,\n",
       "        0., 0., 0., 3., 2., 2., 2., 3., 2., 0., 3., 1., 3., 2., 2., 2., 1., 3.,\n",
       "        2., 0., 3., 3., 1., 3., 2., 3., 2., 0., 3., 3., 3., 3., 3., 3., 3., 1.,\n",
       "        3., 3., 1., 3., 1., 3., 3., 3., 1., 3., 2., 3., 3., 1., 3., 3., 3., 1.,\n",
       "        1., 0., 2., 0., 2., 3., 3., 3., 1., 3., 0., 3., 0., 0., 3., 0., 0., 0.,\n",
       "        2., 0., 3., 3., 0., 3., 3., 3., 0., 2., 3., 3., 2., 0., 2., 2., 2., 2.,\n",
       "        0., 2., 2., 2., 0., 1., 0., 0., 0., 3., 3., 3., 2., 3., 0., 2., 3., 3.,\n",
       "        3., 1., 1., 0., 0., 1., 3., 0., 0., 0., 1., 0., 0., 0., 0., 3., 0., 0.,\n",
       "        2., 3., 2., 3., 2., 1., 0., 3., 3., 0., 0., 0., 0., 2., 0., 1., 0., 0.,\n",
       "        0., 0., 3., 1., 0., 0., 2., 3., 1., 0., 3., 3., 3., 3., 3., 1., 2., 2.,\n",
       "        0., 3., 3., 3., 3., 3., 0., 1., 3., 0., 0., 3., 2., 1., 1., 3., 3., 3.,\n",
       "        0., 0., 0., 3., 0., 2., 1., 1., 1., 0., 0., 0., 0., 2., 3., 3., 2., 0.,\n",
       "        0., 1., 1., 0., 2., 0., 2., 2., 1., 1., 1., 0., 1., 3., 3., 3., 2., 1.,\n",
       "        1., 0., 2., 0., 2., 0., 0., 3., 1., 3., 2., 3., 1., 1., 0., 1., 0., 2.,\n",
       "        1., 1., 0., 2., 2., 1., 0., 2., 2., 2., 1., 3., 2., 1., 3., 0., 2., 2.,\n",
       "        2., 1., 1., 1., 0., 2., 3., 1., 3., 2., 1., 1., 3., 2., 1., 3., 3., 3.,\n",
       "        1., 3., 2., 3., 0., 0., 3., 3., 2., 2., 0., 2., 2., 1., 3., 3., 1., 1.,\n",
       "        1., 1., 3., 1., 1., 1., 0., 1., 0., 3., 3., 1., 3., 3., 1., 1., 2., 1.,\n",
       "        0., 2., 0., 2., 2., 1., 3., 3., 1., 1., 0., 1., 2., 3., 2., 1., 1., 0.,\n",
       "        2., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 2., 2., 0., 2., 0., 1., 0.,\n",
       "        2., 1., 3., 2., 3., 2., 2., 3., 1., 1., 3., 2., 1., 1., 3., 1., 1., 0.,\n",
       "        2., 1., 0., 1., 0., 2., 3., 2., 3., 2., 2., 1., 2., 0., 2., 0., 2., 0.,\n",
       "        0., 2., 1., 0., 3., 2., 3., 0., 0., 1., 3., 3., 1., 3., 3., 2., 0., 0.,\n",
       "        2., 2., 0., 0., 3., 2., 1., 1., 1., 0., 1., 3., 0., 3., 2., 3., 2., 1.,\n",
       "        1., 0., 2., 2., 1., 0., 1., 3., 2., 3., 2., 1., 0., 0., 2., 2., 3., 0.,\n",
       "        1., 3., 3., 3., 2., 2., 0., 3., 3., 1., 0., 3., 0., 0., 1., 1., 1., 0.,\n",
       "        3., 3., 3., 0., 3., 3., 1., 1., 1., 1., 0., 1., 0., 0., 3., 0., 3., 0.,\n",
       "        0., 2., 2., 3., 2., 0., 2., 3., 2., 1., 3., 0., 3., 0., 3., 1., 1., 1.,\n",
       "        1., 0., 3., 3., 3., 3., 0., 1., 3., 2., 0., 3., 0., 0., 2., 0., 0., 1.,\n",
       "        0., 1., 2., 2., 0., 2., 2., 3., 3., 1., 0., 0., 0., 2., 2., 0., 0., 3.,\n",
       "        3., 0., 0., 2., 1., 3., 1., 0., 2., 0., 0., 0., 2., 1., 0., 2., 0., 0.,\n",
       "        3., 3., 3., 3., 0., 0., 1., 1., 1., 0., 0., 1., 3., 3., 3., 0., 3., 3.,\n",
       "        3., 2., 0., 3., 3., 1., 1., 0., 0., 0., 2., 1., 0., 2., 0., 0., 0., 3.,\n",
       "        3., 2., 0., 0., 0., 3., 3., 3., 3., 0., 0., 1., 1., 1., 2., 3., 1., 3.,\n",
       "        0., 3., 3., 3., 2., 3., 3., 3., 1., 1., 0., 0., 0., 0., 1., 3., 1., 3.,\n",
       "        3., 0., 0., 2., 1., 0., 3., 3., 0., 3., 0., 3., 3., 0., 3., 0., 1., 3.,\n",
       "        0., 3., 1., 3., 1., 1., 3., 1., 0., 1., 0., 3., 3., 3., 0., 0., 0., 0.,\n",
       "        3., 0., 0., 3., 3., 2., 1., 3., 0., 3., 3., 0., 0., 0., 1., 0., 2., 3.,\n",
       "        2., 0., 2., 1., 2., 1., 3., 2., 3., 2., 0., 0., 2., 2., 0., 2., 2., 1.,\n",
       "        0., 3., 0., 3., 0., 0., 3., 1., 3., 2., 0., 0., 3., 2., 1., 1., 0., 2.,\n",
       "        2., 0., 0., 0., 2., 2., 0., 2., 3., 1., 0., 3., 3., 0., 0., 2., 3., 3.,\n",
       "        1., 3., 3., 3., 3., 2., 2., 2., 0., 2., 0., 2., 2., 2., 2., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 2., 2., 2., 0., 0., 0., 2., 1., 3., 3., 1., 1., 0., 2.,\n",
       "        2., 0., 0., 2., 0., 2., 2., 3., 2., 0., 1., 0., 1., 3., 3., 2., 0., 0.,\n",
       "        1., 3., 2., 0., 2., 1., 3., 3., 3., 2., 0., 0., 0., 2., 0., 3., 2., 0.,\n",
       "        3., 3., 0., 0., 2., 0., 0., 3., 3., 3., 0., 3., 1., 0., 2., 0., 0., 1.,\n",
       "        0., 3., 0., 2., 1., 0., 3., 0., 3., 0., 0., 1., 1., 3., 2., 0., 1., 0.,\n",
       "        2., 0., 2., 1., 0., 2., 0., 3., 0., 2., 0., 3., 2., 3., 3., 1., 0., 2.,\n",
       "        3., 0., 0., 3., 3., 3., 3., 3., 0., 0., 3., 3., 0., 0., 0., 3., 1., 0.,\n",
       "        0., 1., 3., 0., 0., 3., 0., 0., 0., 2., 0., 3., 0., 2., 3., 0., 0., 1.,\n",
       "        0., 3., 3., 3., 0., 1., 0., 2., 0., 3., 2., 0., 0., 0., 3., 0., 0., 3.,\n",
       "        0., 3., 2., 0., 0., 2., 3., 3., 3., 2., 0., 2., 0., 3., 3., 3., 2., 1.,\n",
       "        3., 3., 1., 0., 3., 0., 0., 3., 0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_2300\\752960707.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([734.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 266.]),\n",
       " array([0.        , 0.1       , 0.2       , 0.30000001, 0.40000001,\n",
       "        0.5       , 0.60000002, 0.69999999, 0.80000001, 0.89999998,\n",
       "        1.        ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code = []\n",
    "noise = Variable(torch.randn((1,1000))).cuda()\n",
    "out = generator(noise)\n",
    "out = out.cpu().detach().numpy()\n",
    "for i in out[0]:\n",
    "    if i > 4:\n",
    "        code.append(4)\n",
    "    elif i < 0:\n",
    "        code.append(0)\n",
    "    else:\n",
    "        code.append(np.round(i))\n",
    "plt.hist(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([367.,   0.,   0., 179.,   0.,   0., 191.,   0.,   0., 263.]),\n",
       " array([0.        , 0.30000001, 0.60000002, 0.89999998, 1.20000005,\n",
       "        1.5       , 1.79999995, 2.0999999 , 2.4000001 , 2.70000005,\n",
       "        3.        ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(next(iter(dataloader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Linear(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = torch.randn(1000, 100)\n",
    "layer(noise).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_new(nn.Module):\n",
    "    def __init__(self,  latent_vars, gen_dim, max_seq_len, annotated=False, res_layers=5):\n",
    "        super(Generator_new, self).__init__()\n",
    "        self.input_size = latent_vars.shape\n",
    "        self.output_size = gen_dim * max_seq_len\n",
    "        self.seq_len = max_seq_len\n",
    "        self.gen_dim = gen_dim\n",
    "        self.res_layer = res_layers\n",
    "        #self.conv1 = nn.Conv1d(3,6,5,1)\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv1d(1,gen_dim,5,1, padding = 'same'),\n",
    "                        nn.ReLU())\n",
    "        self.con1 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con2 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con3 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con4 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con5 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv1d(gen_dim,1,5,1, padding = 'same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Softmax())\n",
    "        # self.con_array = [\n",
    "        #     self.con1,\n",
    "        #     self.con2,\n",
    "        #     self.con3,\n",
    "        #     self.con4,\n",
    "        #     self.con5,\n",
    "        # ]\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Softmax()#nn.Sigmoid()\n",
    "        self.linear = nn.Linear(100,1)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        _input = self.conv1(x)#torch.reshape(x,(-1,self.gen_dim,self.seq_len))     \n",
    "        \n",
    "        out = self.con1(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con1(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con2(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con3(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con4(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con5(_input)\n",
    "        out = self.relu(out)\n",
    "        out = self.sigmoid(_input + 0.3 * out)  \n",
    "        # for i in range(self.res_layer):\n",
    "        #     output = self.res_block(_input.float(),i, 0.3)\n",
    "        #     _input = output\n",
    "        #output = self.conv2(out)\n",
    "        output = torch.transpose(out, 0, 1)\n",
    "        output = self.linear(output) \n",
    "        return torch.transpose(output, 0, 1)\n",
    "    \n",
    "    def res_block(self,_input, index, downsample = 0):\n",
    "        res = _input\n",
    "        out = self.con_array[index](res)\n",
    "        out = self.relu(out)\n",
    "        if downsample:\n",
    "            res = res * downsample\n",
    "            out = out + res\n",
    "        return out\n",
    "\n",
    "        \n",
    "class Critical_new(nn.Module):\n",
    "    def __init__(self,  latent_vars, gen_dim, max_seq_len, annotated=False, res_layers=5):\n",
    "        super(Critical_new, self).__init__()\n",
    "        self.input_size = latent_vars.shape\n",
    "        self.output_size = gen_dim * max_seq_len\n",
    "        self.seq_len = max_seq_len\n",
    "        self.gen_dim = gen_dim\n",
    "        self.res_layer = res_layers\n",
    "        #self.conv1 = nn.Conv1d(3,6,5,1)\n",
    "        self.conv1 = nn.Conv1d(gen_dim,1,5,1, padding = 'same')\n",
    "        self.con1 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con2 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con3 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con4 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con5 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv1d(1, gen_dim,5,1, padding = 'same'),\n",
    "                        nn.ReLU())\n",
    "        # self.con_array = [\n",
    "        #     self.con1,\n",
    "        #     self.con2,\n",
    "        #     self.con3,\n",
    "        #     self.con4,\n",
    "        #     self.con5,\n",
    "        # ]\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        _input = x\n",
    "        out = self.conv2(_input)\n",
    "        \n",
    "        out = self.con1(out)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con1(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con2(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con3(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con4(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = out\n",
    "\n",
    "        out = self.con5(_input)\n",
    "        out = self.relu(out)\n",
    "        out = _input + 0.3 * out\n",
    "        # for i in range(self.res_layer):\n",
    "        #     output = self.res_block(_input.float(),i, 0.3)\n",
    "        #     _input = output\n",
    "        # #output = torch.reshape(output,(-1,1))\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        return out #self.sigmoid(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
