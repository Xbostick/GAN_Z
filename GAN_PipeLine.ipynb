{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "import time\n",
    "_wandb = True\n",
    "Load = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxbostick\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\work\\GAN_Z\\wandb\\run-20230904_191722-7kgq1l70</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xbostick/GAN-Z/runs/7kgq1l70' target=\"_blank\">valiant-sky-33</a></strong> to <a href='https://wandb.ai/xbostick/GAN-Z' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xbostick/GAN-Z' target=\"_blank\">https://wandb.ai/xbostick/GAN-Z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xbostick/GAN-Z/runs/7kgq1l70' target=\"_blank\">https://wandb.ai/xbostick/GAN-Z/runs/7kgq1l70</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if _wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"GAN-Z\",\n",
    "        \n",
    "        # track hyperparameters and run metadata\n",
    "        config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"GAN\",\n",
    "        \"dataset\": \"chr1\",\n",
    "        \"epochs\": 300,\n",
    "        }\n",
    "\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False # GPU Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = False # Generate generic data on the fly (ignores data_loc and data_start args)\n",
    "data_loc = Path(\"./data/\") # Data location\n",
    "epoch = 300\n",
    "disc_iters = 5 # Number of iterations to train discriminator for at each epoch\n",
    "latent_dim = 5 # Size of latent space\n",
    "gen_dim = 100 # Generator dimension parameter\n",
    "disc_dim = 100 # Discriminator dimension parameter\n",
    "gen_layers = 5\n",
    "disc_layer = 5\n",
    "batch_size = 100\n",
    "max_seq_len = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " gen_data = lib.models.resnet_generator(latent_vars, args.gen_dim, args.max_seq_len, data_enc_dim, args.annotate)\n",
    "  data_enc_dim = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_DNA(part):\n",
    "    seq = []\n",
    "    for i in part:\n",
    "        match i:\n",
    "                case 0:\n",
    "                    seq.append([1,0,0,0,0])\n",
    "                case 1:\n",
    "                    seq.append([0,1,0,0,0])\n",
    "                case 2:\n",
    "                    seq.append([0,0,1,0,0])\n",
    "                case 3:\n",
    "                    seq.append([0,0,0,1,0])\n",
    "                case 4:\n",
    "                    seq.append([0,0,0,0,1])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_ohe_DNA(part):\n",
    "    seq = []\n",
    "    for i in part:\n",
    "        match i:\n",
    "                case [1,0,0,0,0]:\n",
    "                    seq.append(0)\n",
    "                case [0,1,0,0,0]:\n",
    "                    seq.append(1)\n",
    "                case [0,0,1,0,0]:\n",
    "                    seq.append(2)\n",
    "                case [0,0,0,1,0]:\n",
    "                    seq.append(3)\n",
    "                case [0,0,0,0,1]:\n",
    "                    seq.append(4)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_vocab = {\"A\":0,\n",
    "             \"C\":1,\n",
    "             \"G\":2,\n",
    "             \"T\":3,\n",
    "             \"N\":4} # catch-all auxiliary token\n",
    "\n",
    "class GenomicData(Dataset):\n",
    "    def __init__(self, path, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        with open(path) as fasta_file:  # Will close handle cleanly\n",
    "            seq_record = {}\n",
    "            seq_record[\"lengths\"] = []\n",
    "            seq_record[\"seq\"] = []\n",
    "\n",
    "            for seq_rec in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
    "                seq_record[\"lengths\"].append(len(seq_rec.seq))\n",
    "                seq_record[\"seq\"].append(seq_rec.seq)\n",
    "        self.len = int(seq_record[\"lengths\"][0])\n",
    "        self.coded_seq = []\n",
    "        for one in list(seq_record[\"seq\"][0]):\n",
    "            try:\n",
    "                self.coded_seq.append(dna_vocab[one.upper()])\n",
    "            except:\n",
    "                print(one)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.len/self.seq_len)#int(np.round((self.len - self.seq_len)/100))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(ohe_DNA(self.coded_seq[idx* self.seq_len:(idx+1)*self.seq_len]))\n",
    "\n",
    "\n",
    "GenData = GenomicData(\"./data/chr1.fa\", max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenData[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 сверточных слоев с skip connection residual factor 0.3.\n",
    "В сверточном слое 100 фильтров ядро 5 stribe 1\n",
    "adam optimazer и wasserstein loss(WGAN) and lr 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_new(nn.Module):\n",
    "    def __init__(self,  latent_vars, gen_dim, max_seq_len, annotated=False, res_layers=5):\n",
    "        super(Generator_new, self).__init__()\n",
    "        self.input_size = latent_vars.shape\n",
    "        self.output_size = gen_dim * max_seq_len\n",
    "        self.seq_len = max_seq_len\n",
    "        self.gen_dim = gen_dim\n",
    "        self.res_layer = res_layers\n",
    "        #self.conv1 = nn.Conv1d(3,6,5,1)\n",
    "        self.con1 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con2 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con3 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con4 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con5 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv1d(gen_dim,5,5,1, padding = 'same'),\n",
    "                        nn.ReLU())\n",
    "        # self.con_array = [\n",
    "        #     self.con1,\n",
    "        #     self.con2,\n",
    "        #     self.con3,\n",
    "        #     self.con4,\n",
    "        #     self.con5,\n",
    "        # ]\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()#nn.Sigmoid()\n",
    "        self.linear = nn.Linear(1,100)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        x = self.linear(x) \n",
    "        x = torch.transpose(x , 0, 1)\n",
    "        _input = x\n",
    "        \n",
    "        out = self.con1(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "        \n",
    "        out = self.con2(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con3(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con4(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con5(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        output = self.conv1(_input)\n",
    "        output = torch.transpose(output, 0, 1)\n",
    "        output = self.softmax(output)\n",
    "        output = torch.transpose(output, 0, 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critical_new(nn.Module):\n",
    "    def __init__(self,  latent_vars, gen_dim, max_seq_len, annotated=False, res_layers=5):\n",
    "        super(Critical_new, self).__init__()\n",
    "        self.input_size = latent_vars.shape\n",
    "        self.output_size = gen_dim * max_seq_len\n",
    "        self.seq_len = max_seq_len\n",
    "        self.gen_dim = gen_dim\n",
    "        self.res_layer = res_layers\n",
    "        #self.conv1 = nn.Conv1d(3,6,5,1)\n",
    "        self.con1 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con2 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con3 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con4 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.con5 = nn.Conv1d(gen_dim ,gen_dim,5,1, padding = 'same')\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv1d(5, gen_dim,5,1, padding = 'same'),\n",
    "                        nn.ReLU())\n",
    "        # self.con_array = [\n",
    "        #     self.con1,\n",
    "        #     self.con2,\n",
    "        #     self.con3,\n",
    "        #     self.con4,\n",
    "        #     self.con5,\n",
    "        # ]\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(100,1)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        _input = self.conv1(x)\n",
    "        \n",
    "        out = self.con1(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con2(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con3(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con4(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        out = self.con5(_input)\n",
    "        out = _input + 0.3 * out\n",
    "        _input = self.relu(out)\n",
    "\n",
    "        output = torch.transpose(_input, 0, 1)\n",
    "        output = self.linear(output)\n",
    "        output = torch.transpose(output, 0, 1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vars = torch.randn([10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator= Generator_new(latent_vars,gen_dim,max_seq_len)\n",
    "discriminator = Critical_new(latent_vars,gen_dim,max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Load:\n",
    "    generator.load_state_dict(torch.load(\"./models/generator.mod\"))\n",
    "    generator.eval()\n",
    "\n",
    "    discriminator.load_state_dict(torch.load(\"./models/discriminator.mod\"))\n",
    "    discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.cuda()\n",
    "# out = generator(z)\n",
    "# discriminator.cuda()\n",
    "# discriminator(out).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    #adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggested default - beta parameters (decay of first order momentum of gradients)\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "# suggested default - learning rate\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas = (b1,b2) )\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _wandb:\n",
    "    wandb.watch(generator, log_freq=100)\n",
    "    wandb.watch(discriminator, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad(model):\n",
    "    for param in model.parameters():\n",
    "        param.grad = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1)))\n",
    "        # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples))\n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    fake = Variable(Tensor(1,1000).fill_(1.0), requires_grad=False)\n",
    "        # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "            outputs=d_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=fake,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WandbLogging(LogData,StartTime, Delay):\n",
    "    NowTime = time.perf_counter()\n",
    "    if NowTime - StartTime > Delay:\n",
    "        wandb.log(LogData)\n",
    "        return NowTime\n",
    "    else:\n",
    "        return StartTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()\n",
    "n_epochs = 10 # suggested default = 200\n",
    "for epoch in range(n_epochs):\n",
    "    dataloader = None\n",
    "    dataloader = DataLoader(GenData,6,drop_last=True, shuffle = True)\n",
    "    StartTime = time.perf_counter()\n",
    "    for i in tqdm(dataloader):\n",
    "        train_data = i.cuda()\n",
    "        #   Critical forward-loss-backward-update\n",
    "        for j in range(5):\n",
    "\n",
    "            # Sample data\n",
    "            noise = Variable(torch.randn((1,1000))).cuda()# Random sampling Tensor(batch_size, latent_dim) of Gaussian distribution\n",
    "        \n",
    "            # real_data = torch.reshape(train_data[j],(1,1000))\n",
    "            real_data = torch.transpose(train_data[j],0,1)\n",
    "            real_data = Variable(real_data)\n",
    "\n",
    "            #generic\n",
    "            fake_data = generator(noise)\n",
    "            critics_real = discriminator(real_data)\n",
    "            critics_fake = discriminator(fake_data)\n",
    "\n",
    "            gradient_penalty = compute_gradient_penalty(discriminator, real_data, fake_data)\n",
    "            critics_loss = -torch.mean(critics_real) + torch.mean(critics_fake) + 10 * gradient_penalty\n",
    "            \n",
    "            critics_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Weight clipping\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            # Housekeeping - reset gradient\n",
    "            reset_grad(generator)\n",
    "            reset_grad(discriminator)\n",
    "\n",
    "        #   Generator forward-loss-backward-update\n",
    "        \n",
    "        noise = Variable(torch.randn((1,1000))).cuda()# Random sampling Tensor(batch_size, latent_dim) of Gaussian distribution\n",
    "        #real_data = torch.reshape(train_data[j+1],(1,1000))\n",
    "        real_data = Variable(real_data)\n",
    "        #real_data = imgs[\"generator\"].type(Tensor)\n",
    "\n",
    "        fake_data = generator(noise)\n",
    "        critics_fake = discriminator(fake_data)\n",
    "\n",
    "        generator_loss = -torch.mean(critics_fake)\n",
    "        \n",
    "        generator_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        reset_grad(generator)\n",
    "        reset_grad(discriminator)\n",
    "\n",
    "        if _wandb:\n",
    "            table = wandb.Histogram(np_histogram = np.histogram(np.argmax(generator(noise).detach().cpu().numpy(),0)))\n",
    "            WandbLogDict = {\"Epoch\": epoch+1, \"Critics_loss\": critics_loss.item(), \"Generator_loss\": generator_loss.item(),\"Results\": table}\n",
    "            StartTime = WandbLogging(WandbLogDict, StartTime, 120)\n",
    "            \n",
    "\n",
    "    print('D_loss: {}; G_loss: {}'\n",
    "              .format(critics_loss.item(),  generator_loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Critics_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅███████████</td></tr><tr><td>Generator_loss</td><td>█▇▁▄█▆▇▇▆▅▄▄▄▃▅▃▅▄▄▄▄▆▅▂▄▃▆▆▅▄▃▅▄▂▇▅▅▅▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Critics_loss</td><td>-0.00391</td></tr><tr><td>Epoch</td><td>3</td></tr><tr><td>Generator_loss</td><td>-0.03669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">valiant-sky-33</strong> at: <a href='https://wandb.ai/xbostick/GAN-Z/runs/7kgq1l70' target=\"_blank\">https://wandb.ai/xbostick/GAN-Z/runs/7kgq1l70</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230904_191722-7kgq1l70\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), \"./models/generator1.mod\")\n",
    "torch.save(discriminator.state_dict(), \"./models/discriminator1.mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(generator):\n",
    "    noise = Variable(torch.randn((1,1000))).cuda()\n",
    "    OheSeq = generator(noise).detach().cpu().numpy()\n",
    "    return np.argmax(OheSeq,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_vocab_revers = {0: \"A\",\n",
    "             1:\"C\",\n",
    "             2:\"G\",\n",
    "             3:\"T\",\n",
    "             4:\"N\"}\n",
    "def Gseq2file(seq):\n",
    "    wr = []\n",
    "    for i in seq:\n",
    "        wr.extend(dna_vocab_revers[i])\n",
    "    with open(\"./check.txt\", 'w+') as f:\n",
    "        f.write(wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_6340\\752960707.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    }
   ],
   "source": [
    "wr = []\n",
    "seq = generate_seq(generator)\n",
    "for i in seq:\n",
    "        wr.extend(dna_vocab_revers[i])\n",
    "with open(\"./check.txt\", 'w+') as f:\n",
    "        f.write(''.join(wr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each sequence, the model recapitulated\n",
    "not only the properties related to basic sequence composition, such as\n",
    "\n",
    "\n",
    "GC content (Fig. 2c: average GC content within 1.1% of values in natural\n",
    "sequences) and \n",
    "\n",
    "UTR sizes (Fig. 2d, e: average length of generated UTRs\n",
    "within 8 bp of natural ones) but also the known \n",
    "\n",
    "DNA regulatory grammar (see Fig. 1a). \n",
    "\n",
    "This included (i) canonical motifs of transcription factor binding sites (TFBS) from the Jaspar database48, \n",
    "\n",
    "identified (qvalue < 0.05) using FIMO49, and \n",
    "\n",
    "core promoter elements comprising the TATA box50,51 in promoters (ii) Kozak sequences in 5′ UTRs52,53, (iii) termination related motifs, including positioning, efficiency, and poly-AT\n",
    "motifs6,54 in 3′ UTRs and terminators, (iv) previous deep learninguncovered expression-related motifs and motif associations7, as well as\n",
    "(v) positions predicted to be depleted of nucleosome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GC content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GC_Content(ohe_seq):\n",
    "    return (sum(ohe_seq == dna_vocab[\"G\"]) + sum(ohe_seq == dna_vocab[\"C\"]))/len(ohe_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(GenData,1,drop_last=True, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b58d86ebff47a8b456aa8ff2a1b605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_6340\\752960707.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3855094905094905\n",
      "0.3542147852147852\n"
     ]
    }
   ],
   "source": [
    "real = []\n",
    "gen = []\n",
    "for num,batch in tqdm(enumerate(dataloader)):\n",
    "    real.append(GC_Content(np.array(reverse_ohe_DNA(batch[0].tolist()))))\n",
    "    gen.append(GC_Content(generate_seq(generator)))\n",
    "    if num >= 1000:\n",
    "        break\n",
    "print(np.mean(real))\n",
    "print(np.mean(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kozak seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_dna_vocab =   {0:0,\n",
    "                    1:3,\n",
    "                    2:2,\n",
    "                    3:1,\n",
    "                    4:4}\n",
    "\n",
    "def ohe_swap(seq):\n",
    "    swaped = []\n",
    "    for i in seq:\n",
    "        swaped.append(swap_dna_vocab[i])\n",
    "    return swaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kozak Consensus Scoring System\n",
    "\n",
    "#0=A, 1=T, 2=G, 3=C, 4=N (Missing)\n",
    "weights = np.array([\n",
    "       [0.04210526, 0.        , 0.03157895, 0.05263158, 0.        ],\n",
    "       [0.04210526, 0.05263158, 0.10526316, 0.0625    , 0.        ],\n",
    "       [0.03157895, 0.04210526, 0.05263158, 0.07368421, 0.        ],\n",
    "       [0.03157895, 0.01052632, 0.04210526, 0.05263158, 0.        ],\n",
    "       [0.08421053, 0.07368421, 0.18947368, 0.10526316, 0.        ],\n",
    "       [0.04210526, 0.05263158, 0.05263158, 0.08421053, 0.        ],\n",
    "       [0.12631579, 0.0625    , 0.12631579, 0.21052632, 0.        ],\n",
    "       [0.83157895, 0.12631579, 0.65263158, 0.16842105, 0.        ],\n",
    "       [0.15789474, 0.06315789, 0.11578947, 0.2       , 0.        ],\n",
    "       [0.21052632, 0.09473684, 0.31578947, 0.51578947, 0.        ],\n",
    "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
    "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
    "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
    "       [0.24210526, 0.16666667, 0.53684211, 0.13684211, 0.        ],\n",
    "       [0.15789474, 0.09473684, 0.09473684, 0.24210526, 0.        ],\n",
    "       [0.05263158, 0.08421053, 0.14736842, 0.09473684, 0.        ],\n",
    "       [0.07216495, 0.05263158, 0.10526316, 0.06315789, 0.        ],\n",
    "       [0.        , 0.        , 0.        , 0.05263158, 0.        ],\n",
    "       [0.05263158, 0.05263158, 0.10526316, 0.09473684, 0.        ],\n",
    "       [0.04210526, 0.03157895, 0.05263158, 0.04210526, 0.        ],\n",
    "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
    "       [0.04210526, 0.04210526, 0.08421053, 0.07368421, 0.        ],\n",
    "       [0.0625    , 0.04210526, 0.09473684, 0.05263158, 0.        ]\n",
    "])\n",
    "\n",
    "#Below function scores using consensus kozak motif scores\n",
    "def similarity_score(sequence):\n",
    "                \n",
    "    #We need consistency and flexibility:\n",
    "        \n",
    "    numbers = ohe_swap(sequence)\n",
    "                \n",
    "    \n",
    "    score = 0\n",
    "    for k in np.arange(len(numbers)):\n",
    "        score += weights[k][numbers[k]]\n",
    "            \n",
    "    max_score = np.sum(weights.max(axis=1))\n",
    "    \n",
    "    score = score/max_score\n",
    "    \n",
    "    #Final scoring value: we take the maximum possible score \n",
    "    #calculated, and return our score divided by the maximum (to normalize from range 0 to 1) \n",
    "    \n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_6340\\752960707.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 8793.,     0.,     0.,  1723., 17101., 22599., 26331., 17523.,\n",
       "         5062.,   522.]),\n",
       " array([0.        , 0.09211268, 0.18422535, 0.27633803, 0.3684507 ,\n",
       "        0.46056338, 0.55267606, 0.64478873, 0.73690141, 0.82901409,\n",
       "        0.92112676]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G_s = []\n",
    "R_s = []\n",
    "for num,batch in enumerate(dataloader):\n",
    "    G_seq = generate_seq(generator)\n",
    "    R_seq = np.array(reverse_ohe_DNA(batch[0].tolist()))\n",
    "    for i in range(1000-23):\n",
    "        G_s.append(similarity_score(G_seq[i:i+23]))\n",
    "        R_s.append(similarity_score(R_seq[i:i+23]))\n",
    "    if num > 100:\n",
    "        break\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "columns = 2\n",
    "rows = 1\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.hist(G_s)\n",
    "\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.hist(R_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.08478335039235756, pvalue=4.77338769689e-312, statistic_location=0.0, statistic_sign=-1)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.kstest(G_s,R_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
